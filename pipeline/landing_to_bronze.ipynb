{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91828a74-9aab-44cc-82e3-b43c4b7d1b09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Validando a SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca17ef2c-3861-4586-83a4-5aeef2c31047",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=1083472119584360#setting/sparkui/0615-200540-ukdrqxex/driver-2738637117038505256\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[8]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=1083472119584360#setting/sparkui/0615-200540-ukdrqxex/driver-2738637117038505256\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca4c03c7-379c-402b-bc7a-9caff2d61b15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Conectando Azure ADLS Gen2 no Databricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "957391e0-6bb8-4089-89c9-6002e9429fdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Mostrando os pontos de montagem no cluster Databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00ecd141-5d8a-4222-ba0e-96ef044aa9bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>mountPoint</th><th>source</th><th>encryptionType</th></tr></thead><tbody><tr><td>/databricks-datasets</td><td>databricks-datasets</td><td></td></tr><tr><td>/mnt/datalakefbca7dc4e981b9cb/landing-zone</td><td>wasbs://landing-zone@datalakefbca7dc4e981b9cb.blob.core.windows.net</td><td></td></tr><tr><td>/databricks/mlflow-tracking</td><td>databricks/mlflow-tracking</td><td>sse-s3</td></tr><tr><td>/databricks-results</td><td>databricks-results</td><td>sse-s3</td></tr><tr><td>/mnt/datalakefbca7dc4e981b9cb/gold</td><td>wasbs://gold@datalakefbca7dc4e981b9cb.blob.core.windows.net</td><td></td></tr><tr><td>/databricks/mlflow-registry</td><td>databricks/mlflow-registry</td><td>sse-s3</td></tr><tr><td>/mnt/datalake7eadf73a479de9f7/landing-zone</td><td>wasbs://landing-zone@datalake7eadf73a479de9f7.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalakefbca7dc4e981b9cb/silver</td><td>wasbs://silver@datalakefbca7dc4e981b9cb.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalakec8dc20f3798c1da9/bronze</td><td>wasbs://bronze@datalakec8dc20f3798c1da9.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalakec8dc20f3798c1da9/landing-zone</td><td>wasbs://landing-zone@datalakec8dc20f3798c1da9.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalakefbca7dc4e981b9cb/lading-zone</td><td>wasbs://lading-zone@datalakefbca7dc4e981b9cb.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalakefbca7dc4e981b9cb/bronze</td><td>wasbs://bronze@datalakefbca7dc4e981b9cb.blob.core.windows.net</td><td></td></tr><tr><td>/</td><td>DatabricksRoot</td><td>sse-s3</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "/databricks-datasets",
         "databricks-datasets",
         ""
        ],
        [
         "/mnt/datalakefbca7dc4e981b9cb/landing-zone",
         "wasbs://landing-zone@datalakefbca7dc4e981b9cb.blob.core.windows.net",
         ""
        ],
        [
         "/databricks/mlflow-tracking",
         "databricks/mlflow-tracking",
         "sse-s3"
        ],
        [
         "/databricks-results",
         "databricks-results",
         "sse-s3"
        ],
        [
         "/mnt/datalakefbca7dc4e981b9cb/gold",
         "wasbs://gold@datalakefbca7dc4e981b9cb.blob.core.windows.net",
         ""
        ],
        [
         "/databricks/mlflow-registry",
         "databricks/mlflow-registry",
         "sse-s3"
        ],
        [
         "/mnt/datalake7eadf73a479de9f7/landing-zone",
         "wasbs://landing-zone@datalake7eadf73a479de9f7.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalakefbca7dc4e981b9cb/silver",
         "wasbs://silver@datalakefbca7dc4e981b9cb.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalakec8dc20f3798c1da9/bronze",
         "wasbs://bronze@datalakec8dc20f3798c1da9.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalakec8dc20f3798c1da9/landing-zone",
         "wasbs://landing-zone@datalakec8dc20f3798c1da9.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalakefbca7dc4e981b9cb/lading-zone",
         "wasbs://lading-zone@datalakefbca7dc4e981b9cb.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalakefbca7dc4e981b9cb/bronze",
         "wasbs://bronze@datalakefbca7dc4e981b9cb.blob.core.windows.net",
         ""
        ],
        [
         "/",
         "DatabricksRoot",
         "sse-s3"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "mountPoint",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "source",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "encryptionType",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dbutils.fs.mounts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "505f9e9c-c98b-4145-9eb3-64ee375e30ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Definindo função para montar ADLS com SAS token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bc0cfb2-5bd2-4da0-ae61-2481d6b01d26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "storageAccountName = \"datalake7eadf73a479de9f7\"\n",
    "sasToken = \"sv=2024-11-04&ss=bfqt&srt=sco&sp=rwdlacupyx&se=2025-06-16T03:33:35Z&st=2025-06-15T19:33:35Z&spr=https&sig=fBJfCWK99G%2FGTBY81Y8eNQYEpOxgrzjVSaavlAB0np4%3D\"\n",
    "\n",
    "def mount_adls(blobContainerName):\n",
    "    try:\n",
    "        dbutils.fs.mount(\n",
    "            source = \"wasbs://{}@{}.blob.core.windows.net\".format(blobContainerName, storageAccountName),\n",
    "            mount_point = f\"/mnt/{storageAccountName}/{blobContainerName}\",\n",
    "            extra_configs = {'fs.azure.sas.' + blobContainerName + '.' + storageAccountName + '.blob.core.windows.net': sasToken}\n",
    "        )\n",
    "        print(\"OK!\")\n",
    "    except Exception as e:\n",
    "        print(\"Falha\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06f0c74c-bc22-40ab-b7a5-fee316e1ec65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Montando containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6596855-e29d-493f-b698-13fe4382640f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falha An error occurred while calling o1893.mount.\n: java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/datalake7eadf73a479de9f7/landing-zone; nested exception is: \n\tjava.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/datalake7eadf73a479de9f7/landing-zone\n\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:135)\n\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:69)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.createOrUpdateMount(DBUtilsCore.scala:1053)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.$anonfun$mount$1(DBUtilsCore.scala:1079)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:560)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:657)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:678)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionContext(DBUtilsCore.scala:71)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionTags(DBUtilsCore.scala:71)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:652)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:569)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperationWithResultTags(DBUtilsCore.scala:71)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:560)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:528)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperation(DBUtilsCore.scala:71)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordDbutilsFsOp(DBUtilsCore.scala:135)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:1073)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:195)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:115)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/datalake7eadf73a479de9f7/landing-zone\n\tat scala.Predef$.require(Predef.scala:281)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$insertMount$1(MetadataManager.scala:860)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$modifyAndVerify$2(MetadataManager.scala:1242)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.withRetries(MetadataManager.scala:1015)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.modifyAndVerify(MetadataManager.scala:1231)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.insertMount(MetadataManager.scala:868)\n\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:131)\n\tat com.databricks.backend.daemon.data.server.handler.CEMountHandler.receive(MountHandler.scala:175)\n\tat com.databricks.backend.daemon.data.server.handler.DbfsRequestHandler.receive(DbfsRequestHandler.scala:16)\n\tat com.databricks.backend.daemon.data.server.handler.DbfsRequestHandler.receive$(DbfsRequestHandler.scala:15)\n\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:39)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:54)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:53)\n\tat scala.collection.immutable.List.foreach(List.scala:431)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:53)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend.$anonfun$handleOtherRpc$2(DbfsServerBackend.scala:599)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:290)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:286)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend.com$databricks$backend$daemon$data$server$DbfsServerBackend$$handleOtherRpc(DbfsServerBackend.scala:599)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$1.applyOrElse(DbfsServerBackend.scala:524)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$1.applyOrElse(DbfsServerBackend.scala:431)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:290)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:286)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1033)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:953)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$5(JettyServer.scala:548)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$5$adapted(JettyServer.scala:513)\n\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$12(ActivityContextFactory.scala:860)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:290)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:286)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:53)\n\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$2(ActivityContextFactory.scala:860)\n\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:823)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:805)\n\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withServiceRequestActivity$15(ActivityContextFactory.scala:291)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:290)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:286)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:53)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:291)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:513)\n\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:408)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:110)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:290)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:286)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:110)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:132)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:129)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:92)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n\tat java.lang.Thread.run(Thread.java:840)\n\nOK!\n"
     ]
    }
   ],
   "source": [
    "mount_adls('landing-zone')\n",
    "mount_adls('bronze')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b19e03bb-902d-413d-b747-6a2f014df022",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Processando todos os CSVs da landing-zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f460377f-a455-4bb7-b840-107e7d28fb2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_all_csvs():\n",
    "    landing_zone_path = f\"/mnt/{storageAccountName}/landing-zone\"\n",
    "    bronze_path = f\"/mnt/{storageAccountName}/bronze\"\n",
    "    \n",
    "    files = dbutils.fs.ls(landing_zone_path)\n",
    "    csv_files = [file for file in files if file.name.lower().endswith('.csv')]\n",
    "    \n",
    "    print(f\"Encontrados {len(csv_files)} arquivos CSV\")\n",
    "    \n",
    "    dataframes = {}\n",
    "    \n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            table_name = file.name.replace('.csv', '').lower()\n",
    "            print(f\"Processando: {file.name} -> {table_name}\")\n",
    "            \n",
    "            df = spark.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").csv(file.path)\n",
    "            df.write.format('delta').mode('overwrite').save(f\"{bronze_path}/{table_name}\")\n",
    "            dataframes[table_name] = df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erro em {file.name}: {str(e)}\")\n",
    "    \n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da1003f3-dcdc-4cad-94db-0dfe43e4f232",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrados 14 arquivos CSV\nProcessando: achievement_unlocked.csv -> achievement_unlocked\nProcessando: achievements.csv -> achievements\nProcessando: developers.csv -> developers\nProcessando: dlcs.csv -> dlcs\nProcessando: game_genders.csv -> game_genders\nProcessando: game_platforms.csv -> game_platforms\nProcessando: game_tags.csv -> game_tags\nProcessando: games.csv -> games\nProcessando: genders.csv -> genders\nProcessando: platforms.csv -> platforms\nProcessando: purchases.csv -> purchases\nProcessando: reviews.csv -> reviews\nProcessando: tags.csv -> tags\nProcessando: users.csv -> users\n"
     ]
    }
   ],
   "source": [
    "dataframes_processados = process_all_csvs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08dd4004-eb42-4218-bc80-131984ec2b02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Criando tabelas Delta externas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "002360bc-aee7-49e4-9807-ec7ea8fb7dd4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_external_tables():\n",
    "    bronze_path = f\"/mnt/{storageAccountName}/bronze\"\n",
    "    \n",
    "    try:\n",
    "        bronze_dirs = dbutils.fs.ls(bronze_path)\n",
    "        \n",
    "        for dir_info in bronze_dirs:\n",
    "            if dir_info.isDir():\n",
    "                table_name = dir_info.name.rstrip('/')\n",
    "                \n",
    "                spark.sql(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "                spark.sql(f\"CREATE TABLE {table_name} USING DELTA LOCATION '{dir_info.path}'\")\n",
    "                print(f\"Tabela externa: {table_name}\")\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"Erro: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f94fe080-4005-4782-91d1-e467e96709aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela externa: achievement_unlocked\nTabela externa: achievements\nTabela externa: developers\nTabela externa: dlcs\nTabela externa: game_genders\nTabela externa: game_platforms\nTabela externa: game_tags\nTabela externa: games\nTabela externa: genders\nTabela externa: platforms\nTabela externa: purchases\nTabela externa: reviews\nTabela externa: tags\nTabela externa: users\n"
     ]
    }
   ],
   "source": [
    "create_external_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "916df0b9-951c-452c-afba-87c2e05e1d1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Criando tabelas Delta gerenciadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a86de57-6939-4e60-870c-a7aa9aa63e61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_managed_tables():\n",
    "    database_name = \"pipeline\"\n",
    "    spark.sql(f\"CREATE DATABASE IF NOT EXISTS {database_name}\")\n",
    "    \n",
    "    bronze_path = f\"/mnt/{storageAccountName}/bronze\"\n",
    "    \n",
    "    try:\n",
    "        bronze_dirs = dbutils.fs.ls(bronze_path)\n",
    "        \n",
    "        for dir_info in bronze_dirs:\n",
    "            if dir_info.isDir():\n",
    "                table_name = dir_info.name.rstrip('/')\n",
    "                \n",
    "                df = spark.read.format('delta').load(dir_info.path)\n",
    "                df.write.format('delta').mode('overwrite').saveAsTable(f\"{database_name}.{table_name}\")\n",
    "                print(f\"Tabela gerenciada: {database_name}.{table_name}\")\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"Erro: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "564baa91-ed76-42af-b8bb-c9e432f5b22a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela gerenciada: pipeline.achievement_unlocked\nTabela gerenciada: pipeline.achievements\nTabela gerenciada: pipeline.developers\nTabela gerenciada: pipeline.dlcs\nTabela gerenciada: pipeline.game_genders\nTabela gerenciada: pipeline.game_platforms\nTabela gerenciada: pipeline.game_tags\nTabela gerenciada: pipeline.games\nTabela gerenciada: pipeline.genders\nTabela gerenciada: pipeline.platforms\nTabela gerenciada: pipeline.purchases\nTabela gerenciada: pipeline.reviews\nTabela gerenciada: pipeline.tags\nTabela gerenciada: pipeline.users\n"
     ]
    }
   ],
   "source": [
    "create_managed_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52348267-b75e-4d7f-ae7c-379a72ffb948",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Validando tabelas criadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed6303ad-7c6e-4636-8f8c-2f90fde5c7c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TABELAS GERENCIADAS ===\n+--------+--------------------+-----------+\n|database|           tableName|isTemporary|\n+--------+--------------------+-----------+\n|pipeline|achievement_unlocked|      false|\n|pipeline|        achievements|      false|\n|pipeline|          developers|      false|\n|pipeline|                dlcs|      false|\n|pipeline|        game_genders|      false|\n|pipeline|      game_platforms|      false|\n|pipeline|           game_tags|      false|\n|pipeline|               games|      false|\n|pipeline|             genders|      false|\n|pipeline|           platforms|      false|\n|pipeline|           purchases|      false|\n|pipeline|             reviews|      false|\n|pipeline|                tags|      false|\n|pipeline|               users|      false|\n+--------+--------------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "print(\"=== TABELAS GERENCIADAS ===\")\n",
    "spark.sql(\"SHOW TABLES IN pipeline\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "505cca54-ca62-4af2-9032-5187345f1a62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/mnt/datalake7eadf73a479de9f7/bronze/achievement_unlocked/</td><td>achievement_unlocked/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/datalake7eadf73a479de9f7/bronze/achievements/</td><td>achievements/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/datalake7eadf73a479de9f7/bronze/developers/</td><td>developers/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/datalake7eadf73a479de9f7/bronze/dlcs/</td><td>dlcs/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/datalake7eadf73a479de9f7/bronze/game_genders/</td><td>game_genders/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/datalake7eadf73a479de9f7/bronze/game_platforms/</td><td>game_platforms/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/datalake7eadf73a479de9f7/bronze/game_tags/</td><td>game_tags/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/datalake7eadf73a479de9f7/bronze/games/</td><td>games/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/datalake7eadf73a479de9f7/bronze/genders/</td><td>genders/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/datalake7eadf73a479de9f7/bronze/platforms/</td><td>platforms/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/datalake7eadf73a479de9f7/bronze/purchases/</td><td>purchases/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/datalake7eadf73a479de9f7/bronze/reviews/</td><td>reviews/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/datalake7eadf73a479de9f7/bronze/tags/</td><td>tags/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/datalake7eadf73a479de9f7/bronze/users/</td><td>users/</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/mnt/datalake7eadf73a479de9f7/bronze/achievement_unlocked/",
         "achievement_unlocked/",
         0,
         0
        ],
        [
         "dbfs:/mnt/datalake7eadf73a479de9f7/bronze/achievements/",
         "achievements/",
         0,
         0
        ],
        [
         "dbfs:/mnt/datalake7eadf73a479de9f7/bronze/developers/",
         "developers/",
         0,
         0
        ],
        [
         "dbfs:/mnt/datalake7eadf73a479de9f7/bronze/dlcs/",
         "dlcs/",
         0,
         0
        ],
        [
         "dbfs:/mnt/datalake7eadf73a479de9f7/bronze/game_genders/",
         "game_genders/",
         0,
         0
        ],
        [
         "dbfs:/mnt/datalake7eadf73a479de9f7/bronze/game_platforms/",
         "game_platforms/",
         0,
         0
        ],
        [
         "dbfs:/mnt/datalake7eadf73a479de9f7/bronze/game_tags/",
         "game_tags/",
         0,
         0
        ],
        [
         "dbfs:/mnt/datalake7eadf73a479de9f7/bronze/games/",
         "games/",
         0,
         0
        ],
        [
         "dbfs:/mnt/datalake7eadf73a479de9f7/bronze/genders/",
         "genders/",
         0,
         0
        ],
        [
         "dbfs:/mnt/datalake7eadf73a479de9f7/bronze/platforms/",
         "platforms/",
         0,
         0
        ],
        [
         "dbfs:/mnt/datalake7eadf73a479de9f7/bronze/purchases/",
         "purchases/",
         0,
         0
        ],
        [
         "dbfs:/mnt/datalake7eadf73a479de9f7/bronze/reviews/",
         "reviews/",
         0,
         0
        ],
        [
         "dbfs:/mnt/datalake7eadf73a479de9f7/bronze/tags/",
         "tags/",
         0,
         0
        ],
        [
         "dbfs:/mnt/datalake7eadf73a479de9f7/bronze/users/",
         "users/",
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dbutils.fs.ls(f\"/mnt/{storageAccountName}/bronze\"))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "landing_to_bronze",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}